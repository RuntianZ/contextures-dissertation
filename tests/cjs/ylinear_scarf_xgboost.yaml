# knowledge/ylinear_scarf1 + xgboost
# 89.4296

defaults:
  seed: 0
  folds: 10
  load: True
  save: True
  use_ssh: True
  data_folder: ../datasets
  ckpt_folder: ../ckpt_debug
  result_file: ../results_debug/ylinear_scarf_xgboost.csv
  debug: True

datasets:
  - openml__cjs__14967

recipe:
  ylinear-scarf-xgboost:
    - module: tabzilla_preprocessor
    - module: numerical_standard_scaler
    - module: mixture
      mode: X
      ylinear-scarf:
        - module: ylinear_scarf_learner
          corruption_rate:
            - 0.2
            - 0.4
            - 0.6
          encoder:
            - module: cat_tokenizer
              trainable: True
            - module: mlp_layer
              dims: [256, 256]
              dropout: 0.0
              residual: True
          head: None
          svme: True
          std_coeff:
            - 1 
            - 3
          cov_coeff:
            - 1
            - 3
        - module: fit
          epochs: 200
          lr: 0.0001
          wd: 0.00001
          optimizer: adamw 
          scheduler: none 
          batch_size: 256 
          log_freq: 10 
        - breakpoint: 1 
        - module: transform 
          batch_size: 256 
      xgboost:
        - module: xgboost_embedding_model
          eta: 0.3
          max_depth: 5
          num_boost_round: 50
        - module: pca
          n_components: 10
    - module: standard_scaler
    - module: linear_model
      ridge: 0.01
    - module: eval 


